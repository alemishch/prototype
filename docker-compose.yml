services:
  bot:
    build: .
    container_name: llama-telegram-bot
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./model_cache:/root/.cache/huggingface
      - ./abliteration/llm-abliteration/ablated_model_v1:/app/local_model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped